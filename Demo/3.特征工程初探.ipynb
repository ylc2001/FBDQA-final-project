{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier,\\\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同样载入多个交易日数据\n",
    "但是这次我们多做一点操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/l1/data/FBDQA2021A_MMP_Challenge_ver0.2/data\"\n",
    "\n",
    "sym = 4\n",
    "dates = list(range(24))\n",
    "df = pd.DataFrame()\n",
    "for date in dates:\n",
    "    if (date & 1):\n",
    "        file_name = f\"snapshot_sym{sym}_date{date//2}_am.csv\"\n",
    "    else:\n",
    "        file_name = f\"snapshot_sym{sym}_date{date//2}_am.csv\"\n",
    "    new_df = pd.read_csv(os.path.join(file_dir,file_name))\n",
    "    # 价格+1（从涨跌幅还原到对前收盘价的比例）\n",
    "    new_df['bid1'] = new_df['n_bid1']+1\n",
    "    new_df['bid2'] = new_df['n_bid2']+1\n",
    "    new_df['bid3'] = new_df['n_bid3']+1\n",
    "    new_df['bid4'] = new_df['n_bid4']+1\n",
    "    new_df['bid5'] = new_df['n_bid5']+1\n",
    "    new_df['ask1'] = new_df['n_ask1']+1\n",
    "    new_df['ask2'] = new_df['n_ask2']+1\n",
    "    new_df['ask3'] = new_df['n_ask3']+1\n",
    "    new_df['ask4'] = new_df['n_ask4']+1\n",
    "    new_df['ask5'] = new_df['n_ask5']+1\n",
    "    # 均线特征\n",
    "    new_df['ask1_ma5']  = new_df['ask1'].rolling(window=5,  min_periods=1).mean()\n",
    "    new_df['ask1_ma10'] = new_df['ask1'].rolling(window=10, min_periods=1).mean()\n",
    "    new_df['ask1_ma20'] = new_df['ask1'].rolling(window=20, min_periods=1).mean()\n",
    "    new_df['ask1_ma40'] = new_df['ask1'].rolling(window=40, min_periods=1).mean()\n",
    "    new_df['ask1_ma60'] = new_df['ask1'].rolling(window=60, min_periods=1).mean()\n",
    "    new_df['bid1_ma5']  = new_df['bid1'].rolling(window=5,  min_periods=1).mean()\n",
    "    new_df['bid1_ma10'] = new_df['bid1'].rolling(window=10, min_periods=1).mean()\n",
    "    new_df['bid1_ma20'] = new_df['bid1'].rolling(window=20, min_periods=1).mean()\n",
    "    new_df['bid1_ma40'] = new_df['bid1'].rolling(window=40, min_periods=1).mean()\n",
    "    new_df['bid1_ma60'] = new_df['bid1'].rolling(window=60, min_periods=1).mean()\n",
    "    \n",
    "    # 量价组合\n",
    "    new_df['spread1'] =  new_df['ask1'] - new_df['bid1']\n",
    "    new_df['spread2'] =  new_df['ask2'] - new_df['bid2']\n",
    "    new_df['spread3'] =  new_df['ask3'] - new_df['bid3']\n",
    "    new_df['mid_price1'] =  new_df['ask1'] + new_df['bid1']\n",
    "    new_df['mid_price2'] =  new_df['ask2'] + new_df['bid2']\n",
    "    new_df['mid_price3'] =  new_df['ask3'] + new_df['bid3']\n",
    "    new_df['weighted_ab1'] = (new_df['ask1'] * new_df['n_bsize1'] + new_df['bid1'] * new_df['n_asize1']) / (new_df['n_bsize1'] + new_df['n_asize1'])\n",
    "    new_df['weighted_ab2'] = (new_df['ask2'] * new_df['n_bsize2'] + new_df['bid2'] * new_df['n_asize2']) / (new_df['n_bsize2'] + new_df['n_asize2'])\n",
    "    new_df['weighted_ab3'] = (new_df['ask3'] * new_df['n_bsize3'] + new_df['bid3'] * new_df['n_asize3']) / (new_df['n_bsize3'] + new_df['n_asize3'])\n",
    "\n",
    "    new_df['relative_spread1'] = new_df['spread1'] / new_df['mid_price1']\n",
    "    new_df['relative_spread2'] = new_df['spread2'] / new_df['mid_price2']\n",
    "    new_df['relative_spread3'] = new_df['spread3'] / new_df['mid_price3']\n",
    "    \n",
    "    # 对量取对数\n",
    "    new_df['bsize1'] = new_df['n_bsize1'].map(np.log)\n",
    "    new_df['bsize2'] = new_df['n_bsize2'].map(np.log)\n",
    "    new_df['bsize3'] = new_df['n_bsize3'].map(np.log)\n",
    "    new_df['bsize4'] = new_df['n_bsize4'].map(np.log)\n",
    "    new_df['bsize5'] = new_df['n_bsize5'].map(np.log)\n",
    "    new_df['asize1'] = new_df['n_asize1'].map(np.log)\n",
    "    new_df['asize2'] = new_df['n_asize2'].map(np.log)\n",
    "    new_df['asize3'] = new_df['n_asize3'].map(np.log)\n",
    "    new_df['asize4'] = new_df['n_asize4'].map(np.log)\n",
    "    new_df['asize5'] = new_df['n_asize5'].map(np.log)\n",
    "    new_df['amount'] = new_df['amount_delta'].map(np.log1p)\n",
    "\n",
    "    df = df.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['relative_spread1','relative_spread2','relative_spread3',\n",
    "                     'weighted_ab1','weighted_ab2','weighted_ab3',\n",
    "                     'spread1','spread2','spread3',]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_names = ['bid1','bid2','bid3','bid4','bid5',\n",
    "                     'ask1','ask2','ask3','ask4','ask5',\n",
    "                     'bsize1','bsize2','bsize3','bsize4','bsize5',\n",
    "                     'asize1','asize2','asize3','asize4','asize5',\n",
    "                     'relative_spread1','relative_spread2','relative_spread3',\n",
    "                     'weighted_ab1','weighted_ab2','weighted_ab3',\n",
    "                     'spread1','spread2','spread3','amount',\n",
    "                     'ask1_ma5','ask1_ma10','ask1_ma20','ask1_ma40','ask1_ma60',\n",
    "                     'bid1_ma5','bid1_ma10','bid1_ma20','bid1_ma40','bid1_ma60'\n",
    "                    ]\n",
    "label_col_name = ['label_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_nums = 40000\n",
    "\n",
    "train_data = np.ascontiguousarray(df[feature_col_names][:train_sample_nums].values)\n",
    "train_label = df[label_col_name][:train_sample_nums].values.reshape(-1)\n",
    "\n",
    "test_data = np.ascontiguousarray(df[feature_col_names][train_sample_nums:].values)\n",
    "test_label = df[label_col_name][train_sample_nums:].values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定有无na值\n",
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定有无inf值\n",
    "np.all(np.isfinite(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"在训练集中：\")\n",
    "print(\"标签为0的样本个数：\", sum(train_label == 0))\n",
    "print(\"标签为1的样本个数：\", sum(train_label == 1))\n",
    "print(\"标签为2的样本个数：\", sum(train_label == 2))\n",
    "\n",
    "print(\"在测试集中：\")\n",
    "print(\"标签为0的样本个数：\", sum(test_label == 0))\n",
    "print(\"标签为1的样本个数：\", sum(test_label == 1))\n",
    "print(\"标签为2的样本个数：\", sum(test_label == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## 对样本依据类别加权：\n",
    "model = SVC(class_weight='balanced')\n",
    "model.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "y_hat = model.predict(train_data)\n",
    "y = train_label\n",
    "# 总体准确率：\n",
    "print(\"总体准确率：\", sum(y_hat == y)/len(y_hat))\n",
    "# 所有不为1的标签的召回率（即仅考虑真实标签为上涨或下跌样本是否被正确分类）\n",
    "index = y != 1\n",
    "print(\"训练集上涨下跌召回率：\", sum(y_hat[index]==y[index])/sum(index))\n",
    "# 所有不为1的标签的准确率（即仅考虑预测为上涨或下跌样本是否是正确）\n",
    "index = y_hat != 1\n",
    "print(\"训练集上涨下跌准确率：\", sum(y_hat[index]==y[index])/sum(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 测试集\n",
    "y_hat = model.predict(test_data)\n",
    "y = test_label\n",
    "# 总体准确率：\n",
    "print(\"总体准确率：\", sum(y_hat == y)/len(y_hat))\n",
    "# 所有不为1的标签的召回率（即仅考虑真实标签为上涨或下跌样本是否被正确分类）\n",
    "index = y != 1\n",
    "print(\"测试集上涨下跌召回率：\", sum(y_hat[index]==y[index])/sum(index))\n",
    "# 所有不为1的标签的准确率（即仅考虑预测为上涨或下跌样本是否是正确）\n",
    "index = y_hat != 1\n",
    "print(\"测试集上涨下跌准确率：\", sum(y_hat[index]==y[index])/sum(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = SVC()\n",
    "grid_params = [{'kernel':['rbf','linear'],'C':[0.5,1,5], 'class_weight':['balanced']}]\n",
    "Grid = GridSearchCV(model, grid_params, cv = 5, scoring = 'balanced_accuracy',refit=True, n_jobs = 6)\n",
    "Grid.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "y_hat = Grid.best_estimator_.predict(train_data)\n",
    "y = train_label\n",
    "# 总体准确率：\n",
    "print(\"总体准确率：\", sum(y_hat == y)/len(y_hat))\n",
    "# 所有不为1的标签的召回率（即仅考虑真实标签为上涨或下跌样本是否被正确分类）\n",
    "index = y != 1\n",
    "print(\"训练集上涨下跌召回率：\", sum(y_hat[index]==y[index])/sum(index))\n",
    "# 所有不为1的标签的准确率（即仅考虑预测为上涨或下跌样本是否是正确）\n",
    "index = y_hat != 1\n",
    "print(\"训练集上涨下跌准确率：\", sum(y_hat[index]==y[index])/sum(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 测试集\n",
    "y_hat = Grid.best_estimator_.predict(test_data)\n",
    "y = test_label\n",
    "# 总体准确率：\n",
    "print(\"总体准确率：\", sum(y_hat == y)/len(y_hat))\n",
    "# 所有不为1的标签的召回率（即仅考虑真实标签为上涨或下跌样本是否被正确分类）\n",
    "index = y != 1\n",
    "print(\"测试集上涨下跌召回率：\", sum(y_hat[index]==y[index])/sum(index))\n",
    "# 所有不为1的标签的准确率（即仅考虑预测为上涨或下跌样本是否是正确）\n",
    "index = y_hat != 1\n",
    "print(\"测试集上涨下跌准确率：\", sum(y_hat[index]==y[index])/sum(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
