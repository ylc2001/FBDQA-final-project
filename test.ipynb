{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Using device: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(f\"Using device: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data shape: (2964051, 100, 5), Lebel data shape: (2964051,)\n",
      "train_nums: 2371240, val_nums: 296405, test_nums: 296406\n"
     ]
    }
   ],
   "source": [
    "label_list = ['label_5', 'label_10', 'label_20', 'label_40', 'label_60']\n",
    "\n",
    "with open(f'./np_data/nparray_all_data.pkl', 'rb') as f:\n",
    "    nparray_all_data = pickle.load(f)\n",
    "\n",
    "with open(f'./np_data/nparray_all_label_label_5.pkl', 'rb') as f:\n",
    "    np_label_5 = pickle.load(f)\n",
    "with open(f'./np_data/nparray_all_label_label_10.pkl', 'rb') as f:\n",
    "    np_label_10 = pickle.load(f)\n",
    "with open(f'./np_data/nparray_all_label_label_20.pkl', 'rb') as f:\n",
    "    np_label_20 = pickle.load(f)\n",
    "with open(f'./np_data/nparray_all_label_label_40.pkl', 'rb') as f:\n",
    "    np_label_40 = pickle.load(f)\n",
    "with open(f'./np_data/nparray_all_label_label_60.pkl', 'rb') as f:\n",
    "    np_label_60 = pickle.load(f)\n",
    "\n",
    "n = len(nparray_all_data)\n",
    "##划分训练/测试集\n",
    "train_nums = int(n*0.8)\n",
    "val_nums = int(n*0.1)\n",
    "print(f\"All data shape: {nparray_all_data.shape}, Lebel data shape: {np_label_5.shape}\")\n",
    "print(f'train_nums: {train_nums}, val_nums: {val_nums}, test_nums: {n-train_nums-val_nums}')\n",
    "\n",
    "train_data = nparray_all_data[:train_nums]\n",
    "val_data = nparray_all_data[train_nums:train_nums+val_nums]\n",
    "test_data = nparray_all_data[train_nums+val_nums:]\n",
    "\n",
    "train_label_5 = np_label_5[:train_nums]\n",
    "val_label_5 = np_label_5[train_nums:train_nums+val_nums]\n",
    "test_label_5 = np_label_5[train_nums+val_nums:]\n",
    "train_label_10 = np_label_10[:train_nums]\n",
    "val_label_10 = np_label_10[train_nums:train_nums+val_nums]\n",
    "test_label_10 = np_label_10[train_nums+val_nums:]\n",
    "train_label_20 = np_label_20[:train_nums]\n",
    "val_label_20 = np_label_20[train_nums:train_nums+val_nums]\n",
    "test_label_20 = np_label_20[train_nums+val_nums:]\n",
    "train_label_40 = np_label_40[:train_nums]\n",
    "val_label_40 = np_label_40[train_nums:train_nums+val_nums]\n",
    "test_label_40 = np_label_40[train_nums+val_nums:]\n",
    "train_label_60 = np_label_60[:train_nums]\n",
    "val_label_60 = np_label_60[train_nums:train_nums+val_nums]\n",
    "test_label_60 = np_label_60[train_nums+val_nums:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, data, label,  num_classes, T):\n",
    "        self.T = T\n",
    "\n",
    "        # self.x = torch.tensor(data).to(torch.float32).unsqueeze(1).to(device)\n",
    "        self.x = torch.tensor(data).to(torch.float32).to(device)\n",
    "\n",
    "        # self.y = F.one_hot(torch.tensor(label[T - 1:].astype(np.int64)), num_classes=3)\n",
    "        self.y = torch.tensor(label.astype(np.int64)).to(device)\n",
    "    \n",
    "        self.length = len(self.x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "batch_size = 128\n",
    "dataset_val_5   = Dataset(data=val_data,  label=val_label_5,    num_classes=3, T=100)\n",
    "dataset_val_10  = Dataset(data=val_data,  label=val_label_10,   num_classes=3, T=100)\n",
    "dataset_val_20  = Dataset(data=val_data,  label=val_label_20,   num_classes=3, T=100)\n",
    "dataset_val_40  = Dataset(data=val_data,  label=val_label_40,   num_classes=3, T=100)\n",
    "dataset_val_60  = Dataset(data=val_data,  label=val_label_60,   num_classes=3, T=100)\n",
    "val_loader_5    = torch.utils.data.DataLoader(dataset_val_5,   batch_size=batch_size, shuffle=False)\n",
    "val_loader_10   = torch.utils.data.DataLoader(dataset_val_10,  batch_size=batch_size, shuffle=False)\n",
    "val_loader_20   = torch.utils.data.DataLoader(dataset_val_20,  batch_size=batch_size, shuffle=False)\n",
    "val_loader_40   = torch.utils.data.DataLoader(dataset_val_40,  batch_size=batch_size, shuffle=False)\n",
    "val_loader_60   = torch.utils.data.DataLoader(dataset_val_60,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_loader_list = [val_loader_5, val_loader_10, val_loader_20, val_loader_40, val_loader_60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return F.softmax(out, dim=1)\n",
    "\n",
    "# 模型参数定义\n",
    "input_size = 5\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== label_5 ==========\n",
      "Label: label_5\n",
      "Accuracy: 0.43231052107757967\n",
      "correct: 128139, total: 296405\n",
      "Accuracy_True_False: 0.6339140254739336\n",
      "correct_True_False: 68483, total_tf: 108032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40     54571\n",
      "           1       0.84      0.32      0.46    188373\n",
      "           2       0.31      0.67      0.42     53461\n",
      "\n",
      "    accuracy                           0.43    296405\n",
      "   macro avg       0.48      0.53      0.43    296405\n",
      "weighted avg       0.64      0.43      0.44    296405\n",
      "\n",
      "========== label_10 ==========\n",
      "Label: label_10\n",
      "Accuracy: 0.4436193721428451\n",
      "correct: 131491, total: 296405\n",
      "Accuracy_True_False: 0.5767164788780338\n",
      "correct_True_False: 84711, total_tf: 146885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.55      0.44     74039\n",
      "           1       0.70      0.31      0.43    149520\n",
      "           2       0.37      0.60      0.46     72846\n",
      "\n",
      "    accuracy                           0.44    296405\n",
      "   macro avg       0.48      0.49      0.44    296405\n",
      "weighted avg       0.54      0.44      0.44    296405\n",
      "\n",
      "========== label_20 ==========\n",
      "Label: label_20\n",
      "Accuracy: 0.5445420961184866\n",
      "correct: 161405, total: 296405\n",
      "Accuracy_True_False: 0.33810586133031445\n",
      "correct_True_False: 30463, total_tf: 90099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.31      0.27     44848\n",
      "           1       0.77      0.63      0.69    206306\n",
      "           2       0.25      0.37      0.30     45251\n",
      "\n",
      "    accuracy                           0.54    296405\n",
      "   macro avg       0.42      0.44      0.42    296405\n",
      "weighted avg       0.61      0.54      0.57    296405\n",
      "\n",
      "========== label_40 ==========\n",
      "Label: label_40\n",
      "Accuracy: 0.4568883790759265\n",
      "correct: 135424, total: 296405\n",
      "Accuracy_True_False: 0.3499301855737654\n",
      "correct_True_False: 44860, total_tf: 128197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.37      0.32     64562\n",
      "           1       0.64      0.54      0.59    168208\n",
      "           2       0.30      0.33      0.31     63635\n",
      "\n",
      "    accuracy                           0.46    296405\n",
      "   macro avg       0.41      0.41      0.41    296405\n",
      "weighted avg       0.49      0.46      0.47    296405\n",
      "\n",
      "========== label_60 ==========\n",
      "Label: label_60\n",
      "Accuracy: 0.4343010408056544\n",
      "correct: 128729, total: 296405\n",
      "Accuracy_True_False: 0.32580005175536964\n",
      "correct_True_False: 49101, total_tf: 150709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.31      0.31     75774\n",
      "           1       0.56      0.55      0.55    145696\n",
      "           2       0.32      0.34      0.33     74935\n",
      "\n",
      "    accuracy                           0.43    296405\n",
      "   macro avg       0.40      0.40      0.40    296405\n",
      "weighted avg       0.44      0.43      0.44    296405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in label_list:\n",
    "    print(f\"{'='*10} {name} {'='*10}\")\n",
    "    model.load_state_dict(torch.load(f'best_val_model_lstm_{name}.pth'))\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    correct_tf = 0\n",
    "    total = 0\n",
    "    total_tf = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader_list[label_list.index(name)]:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            for i in range(targets.size(0)):\n",
    "                if targets[i] == 0 or targets[i] == 2:  # 只考虑目标值为0或2的情况\n",
    "                    total_tf += 1\n",
    "                    if predicted[i] == targets[i]:  # 如果预测正确，增加正确的计数\n",
    "                        correct_tf += 1\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            predictions.append(predicted)\n",
    "            labels.append(targets)\n",
    "\n",
    "    print(f'Label: {name}')\n",
    "    print(f'Accuracy: {correct/total}')\n",
    "    print(f'correct: {correct}, total: {total}')\n",
    "    print(f'Accuracy_True_False: {correct_tf/total_tf}')\n",
    "    print(f'correct_True_False: {correct_tf}, total_tf: {total_tf}')\n",
    "    print(classification_report(torch.cat(labels).cpu().numpy(), torch.cat(predictions).cpu().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "companionGLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
